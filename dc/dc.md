# Distributed Computing

## Hadoop

* [WinUtils, Compiled Hadoop for Windows](https://github.com/steveloughran/winutils)

## Spark

* [Spark Releases](https://github.com/apache/spark/releases)
* [Spark 2.0 RC2 README.md](https://github.com/apache/spark/blob/v2.0.0-rc2/README.md)
* [Spark Streaming + Kafka Integration Guide](http://spark.apache.org/docs/latest/streaming-kafka-integration.html) and [the blog about this improvement ](https://databricks.com/blog/2015/03/30/improvements-to-kafka-integration-of-spark-streaming.html)
* [Spark Streaming 2.0 Uses New KafkaConsumer](https://github.com/apache/spark/search?utf8=%E2%9C%93&q=KafkaConsumer)

### Build and Run Spark Locally

* [Quick Start](http://spark.apache.org/docs/latest/quick-start.html)
* [Build Spark](https://spark.apache.org/docs/2.0.0-preview/building-spark.html)
* [Build Spark with Scala 2.11](http://spark.apache.org/docs/latest/building-spark.html#building-for-scala-211)
* [Setup Spark on Intellij IDEA](https://cwiki.apache.org/confluence/display/SPARK/Useful+Developer+Tools#UsefulDeveloperTools-IntelliJ)
* [Spark Snapshot Repo](https://repository.apache.org/content/groups/snapshots/org/apache/spark/)
* [Build and run Spark](http://manuel.kiessling.net/2015/10/17/how-i-build-deploy-and-run-spark/)
* [Building Apache Spark on your Local Machine](http://www.sparktutorials.net/building-apache-spark-on-your-local-machine)
